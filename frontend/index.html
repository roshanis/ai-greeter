<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Greeter</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
        }

        .container {
            text-align: center;
            max-width: 600px;
            padding: 2rem;
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
        }

        h1 {
            font-size: 3rem;
            margin-bottom: 1rem;
            font-weight: 700;
        }

        .subtitle {
            font-size: 1.2rem;
            opacity: 0.9;
            margin-bottom: 2rem;
        }

        .camera-container {
            position: relative;
            margin: 2rem auto;
            width: 320px;
            height: 240px;
            border-radius: 15px;
            overflow: hidden;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.3);
        }

        #camera {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }

        .status {
            font-size: 1.1rem;
            margin: 1.5rem 0;
            padding: 1rem;
            border-radius: 10px;
            font-weight: 500;
        }

        .status.connecting {
            background: rgba(255, 193, 7, 0.2);
            color: #ffc107;
        }

        .status.connected {
            background: rgba(40, 167, 69, 0.2);
            color: #28a745;
        }

        .status.processing {
            background: rgba(0, 123, 255, 0.2);
            color: #007bff;
        }

        .status.disconnected {
            background: rgba(220, 53, 69, 0.2);
            color: #dc3545;
        }

        .vision-status {
            font-size: 0.9rem;
            margin: 1rem 0;
            opacity: 0.8;
        }

        .controls {
            margin: 2rem 0;
        }

        .btn {
            background: rgba(255, 255, 255, 0.2);
            border: 2px solid rgba(255, 255, 255, 0.3);
            color: white;
            padding: 1rem 2rem;
            border-radius: 50px;
            font-size: 1.1rem;
            font-weight: 600;
            cursor: pointer;
            margin: 0 0.5rem;
            transition: all 0.3s ease;
        }

        .btn:hover {
            background: rgba(255, 255, 255, 0.3);
            transform: translateY(-2px);
        }

        .btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        .error {
            background: rgba(220, 53, 69, 0.2);
            color: #dc3545;
            padding: 1rem;
            border-radius: 10px;
            margin: 1rem 0;
            display: none;
        }

        .audio-visualizer {
            height: 60px;
            margin: 1rem 0;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 10px;
            display: flex;
            align-items: center;
            justify-content: center;
            overflow: hidden;
        }

        .audio-bar {
            width: 4px;
            background: rgba(255, 255, 255, 0.6);
            margin: 0 1px;
            border-radius: 2px;
            transition: height 0.1s ease;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸ¤– AI Greeter</h1>
        <p class="subtitle">Your friendly AI companion with vision and voice</p>
        
        <div class="camera-container">
            <video id="camera" autoplay muted playsinline></video>
        </div>
        
        <div id="status" class="status connecting">Initializing...</div>
        <div id="visionStatus" class="vision-status">Vision processing: Inactive</div>
        
        <div class="audio-visualizer" id="audioVisualizer">
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
        </div>
        
        <div class="controls">
            <button id="startBtn" class="btn">Start Conversation</button>
            <button id="stopBtn" class="btn" style="display: none;">Stop</button>
        </div>
        
        <div id="error" class="error"></div>
    </div>

    <script>
        class AIGreeter {
            constructor() {
                this.sessionId = 'session_' + Math.random().toString(36).substr(2, 9);
                this.isActive = false;
                this.mediaRecorder = null;
                this.audioChunks = [];
                this.isRecording = false;
                this.audioContext = null;
                this.stream = null;
                this.visionInterval = null;
                
                this.initializeElements();
                this.setupEventListeners();
            }

            initializeElements() {
                this.cam = document.getElementById('camera');
                this.status = document.getElementById('status');
                this.visionStatus = document.getElementById('visionStatus');
                this.startBtn = document.getElementById('startBtn');
                this.stopBtn = document.getElementById('stopBtn');
                this.error = document.getElementById('error');
                this.audioVisualizer = document.getElementById('audioVisualizer');
            }

            setupEventListeners() {
                this.startBtn.addEventListener('click', () => this.start());
                this.stopBtn.addEventListener('click', () => this.stop());
            }

            generateSessionId() {
                return 'session_' + Math.random().toString(36).substr(2, 9);
            }

            async start() {
                try {
                    this.showStatus('Requesting camera and microphone access...', 'connecting');
                    
                    // Get camera and microphone access
                    this.stream = await navigator.mediaDevices.getUserMedia({
                        video: { width: 640, height: 480 },
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true
                        }
                    });
                    
                    this.cam.srcObject = this.stream;
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    
                    await this.connectToAI();
                    this.startBtn.style.display = 'none';
                    this.stopBtn.style.display = 'inline-block';
                    this.isActive = true;
                    
                    // Start vision processing
                    this.startVisionProcessing();

                } catch (err) {
                    console.error('Error starting session:', err);
                    this.showError(`Failed to start: ${err.message}`);
                    this.stop();
                }
            }

            async connectToAI() {
                this.showStatus('Connecting to AI...', 'connecting');
                
                try {
                    const response = await fetch('/test');
                    if (response.ok) {
                        this.showStatus('Connected! You can start speaking.', 'connected');
                        this.setupAudioProcessing();
                        
                        // Send initial greeting
                        setTimeout(() => {
                            this.sendInitialGreeting();
                        }, 1000);
                    } else {
                        throw new Error('Connection test failed');
                    }
                } catch (error) {
                    this.showError('Failed to connect to AI: ' + error.message);
                }
            }

            async sendInitialGreeting() {
                try {
                    const response = await fetch('/chat', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify({
                            text: "Hello, I just connected. Please greet me!",
                            sessionId: this.sessionId
                        })
                    });

                    if (response.ok) {
                        const data = await response.json();
                        if (data.success && data.response) {
                            await this.speakText(data.response);
                        }
                    }
                } catch (error) {
                    console.error('Error sending initial greeting:', error);
                }
            }

            async setupAudioProcessing() {
                try {
                    // Set up MediaRecorder for voice recording
                    this.mediaRecorder = new MediaRecorder(this.stream, {
                        mimeType: 'audio/webm;codecs=opus'
                    });
                    
                    this.audioChunks = [];
                    this.isRecording = false;
                    
                    this.mediaRecorder.ondataavailable = (event) => {
                        if (event.data.size > 0) {
                            this.audioChunks.push(event.data);
                        }
                    };
                    
                    this.mediaRecorder.onstop = async () => {
                        if (this.audioChunks.length > 0) {
                            const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
                            this.audioChunks = [];
                            await this.processAudio(audioBlob);
                        }
                    };
                    
                    // Set up voice activity detection
                    this.setupVoiceDetection();
                    
                } catch (err) {
                    console.error('Error setting up audio processing:', err);
                    this.showError(`Audio processing error: ${err.message}`);
                }
            }

            setupVoiceDetection() {
                const source = this.audioContext.createMediaStreamSource(this.stream);
                const analyser = this.audioContext.createAnalyser();
                analyser.fftSize = 256;
                source.connect(analyser);
                
                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);
                
                let silenceStart = Date.now();
                let speaking = false;
                
                const checkAudio = () => {
                    if (!this.isActive) return;
                    
                    analyser.getByteFrequencyData(dataArray);
                    const volume = dataArray.reduce((a, b) => a + b) / bufferLength;
                    
                    // Update visualizer
                    this.updateAudioVisualizer(volume);
                    
                    if (volume > 20) { // Voice detected
                        if (!speaking) {
                            speaking = true;
                            this.startRecording();
                        }
                        silenceStart = Date.now();
                    } else { // Silence
                        if (speaking && Date.now() - silenceStart > 1500) { // 1.5 seconds of silence
                            speaking = false;
                            this.stopRecording();
                        }
                    }
                    
                    requestAnimationFrame(checkAudio);
                };
                
                checkAudio();
            }

            updateAudioVisualizer(volume) {
                const bars = this.audioVisualizer.querySelectorAll('.audio-bar');
                const normalizedVolume = Math.min(volume / 50, 1);
                
                bars.forEach((bar, index) => {
                    const height = Math.max(4, normalizedVolume * 50 * (Math.random() * 0.5 + 0.5));
                    bar.style.height = height + 'px';
                });
            }

            startRecording() {
                if (!this.isRecording && this.mediaRecorder.state === 'inactive') {
                    this.audioChunks = [];
                    this.mediaRecorder.start();
                    this.isRecording = true;
                    console.log('Started recording...');
                }
            }

            stopRecording() {
                if (this.isRecording && this.mediaRecorder.state === 'recording') {
                    this.mediaRecorder.stop();
                    this.isRecording = false;
                    console.log('Stopped recording...');
                }
            }

            async processAudio(audioBlob) {
                try {
                    this.showStatus('Processing speech...', 'processing');
                    
                    // Step 1: Speech to Text
                    const transcription = await this.speechToText(audioBlob);
                    if (!transcription || transcription.trim().length < 2) {
                        this.showStatus('Connected! You can start speaking.', 'connected');
                        return;
                    }
                    
                    console.log('Transcription:', transcription);
                    
                    // Step 2: Get AI Response
                    const aiResponse = await this.getAIResponse(transcription);
                    if (!aiResponse) {
                        this.showStatus('Connected! You can start speaking.', 'connected');
                        return;
                    }
                    
                    console.log('AI Response:', aiResponse);
                    
                    // Step 3: Text to Speech
                    await this.speakText(aiResponse);
                    
                    this.showStatus('Connected! You can start speaking.', 'connected');
                    
                } catch (error) {
                    console.error('Error processing audio:', error);
                    this.showError('Error processing speech: ' + error.message);
                    this.showStatus('Connected! You can start speaking.', 'connected');
                }
            }

            async speechToText(audioBlob) {
                try {
                    const response = await fetch('/speech-to-text', {
                        method: 'POST',
                        headers: {
                            'x-session-id': this.sessionId
                        },
                        body: audioBlob
                    });
                    
                    if (!response.ok) {
                        throw new Error(`Speech-to-text failed: ${response.status}`);
                    }
                    
                    const data = await response.json();
                    return data.success ? data.text : null;
                    
                } catch (error) {
                    console.error('Speech-to-text error:', error);
                    return null;
                }
            }

            async getAIResponse(text) {
                try {
                    const response = await fetch('/chat', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify({
                            text: text,
                            sessionId: this.sessionId
                        })
                    });
                    
                    if (!response.ok) {
                        throw new Error(`Chat failed: ${response.status}`);
                    }
                    
                    const data = await response.json();
                    return data.success ? data.response : null;
                    
                } catch (error) {
                    console.error('Chat error:', error);
                    return null;
                }
            }

            async speakText(text) {
                try {
                    this.showStatus('AI is speaking...', 'processing');
                    
                    const response = await fetch('/text-to-speech', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify({ text: text })
                    });
                    
                    if (!response.ok) {
                        throw new Error(`Text-to-speech failed: ${response.status}`);
                    }
                    
                    const audioBlob = await response.blob();
                    await this.playAudioBlob(audioBlob);
                    
                } catch (error) {
                    console.error('Text-to-speech error:', error);
                }
            }

            async playAudioBlob(blob) {
                try {
                    const audio = new Audio();
                    audio.src = URL.createObjectURL(blob);
                    
                    return new Promise((resolve, reject) => {
                        audio.onended = resolve;
                        audio.onerror = reject;
                        audio.play();
                    });
                } catch (error) {
                    console.error('Error playing audio:', error);
                }
            }

            startVisionProcessing() {
                this.visionStatus.textContent = 'Vision processing: Active';
                
                this.visionInterval = setInterval(async () => {
                    if (!this.isActive) return;
                    
                    try {
                        const canvas = document.createElement('canvas');
                        canvas.width = this.cam.videoWidth;
                        canvas.height = this.cam.videoHeight;
                        const ctx = canvas.getContext('2d');
                        ctx.drawImage(this.cam, 0, 0, canvas.width, canvas.height);
                        const base64Image = canvas.toDataURL('image/jpeg', 0.5).split(',')[1];
                        
                        // Send to vision endpoint
                        await fetch('/vision', {
                            method: 'POST',
                            headers: {
                                'Content-Type': 'text/plain',
                                'x-session-id': this.sessionId
                            },
                            body: base64Image
                        });
                        
                    } catch (error) {
                        console.error('Vision processing error:', error);
                    }
                }, 5000); // Every 5 seconds
            }

            showVisionStatus(message) {
                this.visionStatus.textContent = message;
            }

            stop() {
                this.isActive = false;
                
                if (this.visionInterval) {
                    clearInterval(this.visionInterval);
                }
                
                if (this.stream) {
                    this.stream.getTracks().forEach(track => track.stop());
                }
                
                if (this.audioContext) {
                    this.audioContext.close();
                }
                
                this.startBtn.style.display = 'inline-block';
                this.stopBtn.style.display = 'none';
                this.showStatus('Stopped', 'disconnected');
                this.visionStatus.textContent = 'Vision processing: Inactive';
            }

            showStatus(message, type) {
                this.status.textContent = message;
                this.status.className = `status ${type}`;
            }

            showError(message) {
                this.error.textContent = message;
                this.error.style.display = 'block';
                setTimeout(() => {
                    this.error.style.display = 'none';
                }, 5000);
            }
        }

        // Initialize the greeter when the page loads
        document.addEventListener('DOMContentLoaded', () => {
            new AIGreeter();
        });
    </script>
</body>
</html> 